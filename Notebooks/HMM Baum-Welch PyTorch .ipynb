{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Implementation of HMM's Baum-welch's algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_output_occurrence(index, step_gammas, summed_gammas):\n",
    "    filtered_gamma = step_gammas.index_select(1, torch.LongTensor(index))\n",
    "    sum_filtered_gamma = filtered_gamma.sum(dim = 1)\n",
    "    new_obs_prob = torch.div(sum_filtered_gamma, summed_gammas)\n",
    "    return new_obs_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate initial parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta=(A, B, \\pi)$ can be set with random initializations. However, they can also be set using prior information which can speed up the algorithm and steer it towards convergance of desired local maximum.  The following algorithms are used to estimate the initial conditions given prior information about the observed sequence and hidden conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial state distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pi_i = \\frac {count(z_1 = i)} {N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_state_init(sequence):\n",
    "    probabilities = {state: state/len(sequence) for state in Counter(sequence).values()}\n",
    "    hidden_state_initial_probabilities = np.array([prob[1] for prob in sorted(probabilities.items())])\n",
    "    hidden_state_initial_probabilities = torch.from_numpy(hidden_state_initial_probabilities)\n",
    "    return hidden_state_initial_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A(i, j) = P(Z_{t+1} = j | Z_t = i) = \\frac {coun(i \\rightarrow j)} {count(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_mat_init(sequence):\n",
    "    temp = []\n",
    "    sequences = []\n",
    "    sequence_counts = Counter(sequence)\n",
    "    seq_set_length = len(set(sequence))\n",
    "    shape = [seq_set_length, seq_set_length]\n",
    "    transition_mat = torch.zeros(size = shape, dtype = torch.float64)\n",
    "\n",
    "    for i, val in enumerate(sequence):\n",
    "\n",
    "        temp.append(val)\n",
    "\n",
    "        if i != 0:\n",
    "            sequences.append([tuple(temp)])\n",
    "            temp = []\n",
    "            temp.append(val)\n",
    "\n",
    "    transition_sequences = Counter(chain(*sequences))\n",
    "\n",
    "    transition_mat_dict = {key: val/sequence_counts[key[0]] for key, val in transition_sequences.items()}\n",
    "\n",
    "    for key, val in transition_mat_dict.items():\n",
    "        transition_mat[key[0]][key[1]] = val\n",
    "    \n",
    "    return transition_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emission matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$B(j, k) = \\frac {count(z=j \\:\\land\\: x=k)} {count(z=j)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emiss_state_init(hid_seq, obs_seq):\n",
    "    sequence_counts = Counter(hid_seq)\n",
    "    hid_emi_seq = [[x] for x in zip(hid_seq, obs_seq)]\n",
    "    hid_emi_seq_counts = Counter(chain(*hid_emi_seq))\n",
    "    emiss_mat = torch.zeros(size = [len(set(hid_seq)), len(set(obs_seq))], dtype = torch.float64)\n",
    "    emiss_mat_dict = {key:hid_emi_seq_counts[key]/sequence_counts[key[0]] for key, val in hid_emi_seq_counts.items()}\n",
    "    for key, val in emiss_mat_dict.items():\n",
    "        emiss_mat[key[0]][key[1]] = val\n",
    "\n",
    "    return emiss_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\alpha_i(t) = P(Y_1 = y_1,...Y_t = y_t, X_t = i | \\theta) = $\n",
    "1. Initialization step = $\\alpha_i(1) = \\pi_i b_i(y_1) $\n",
    "1. Induction step = $\\alpha_i(t+1) = b_i(y_{t+1}) \\sum_{j=1}^{N} \\alpha_j(t)a_{ij} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(emission_matrix, log = True):  \n",
    "\n",
    "    # α(1,i) = π(i) * B(i, 1)\n",
    "    alpha_initial = pi * emission_matrix[:, obs_sequence[0]]\n",
    "    \n",
    "    if log == True:\n",
    "        # Scaling of initialization step\n",
    "        alpha[:, 0] = torch.div(alpha_initial, alpha_initial.sum())\n",
    "    else:\n",
    "        alpha[:, 0] = alpha_initial\n",
    "        \n",
    "    # Induction steps: bi(y, t+1) * Σ a(j, t) * a(i, j)\n",
    "    for i, obs in enumerate(obs_sequence[1:]):\n",
    "        \n",
    "        # α(t,i) * A(i, j), where α(t,i) = π(i) * B(i, t)\n",
    "        current_probability = torch.matmul(alpha[:, i], A)   \n",
    "        \n",
    "        # Forward probability \n",
    "        forward_probability = torch.mul(current_probability, emission_matrix[:, obs])\n",
    "        \n",
    "        if log == True:\n",
    "            # Scaling & update forward matrix\n",
    "            alpha[:, i+1] = torch.div(forward_probability, forward_probability.sum())\n",
    "        else:\n",
    "            alpha[:, i+1] = forward_probability     \n",
    "                                      \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\beta_i(t) = P(Y_{t+1} = y_{t+1},...Y_T = y_T | X_t = i , \\theta) = $\n",
    "1. Initialization step = $ \\beta_i(T) = 1$\n",
    "2. Induction step = $\\beta_i(t) = {\\sum_{j=1}^{N}}b_j(t+1)a_{ij}b_j(y_{t+1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(observation, log = True):\n",
    "                \n",
    "    # Initialization\n",
    "    beta[:, -1] = torch.from_numpy(np.array([1.0, 1.0]))\n",
    "    \n",
    "    # Induction steps\n",
    "    for i, obs in enumerate(observation[:0:-1]):\n",
    "        \n",
    "        if log == True:\n",
    "            # Induction: Σ A(i, j) * P(X(t+1) | Z) * β(t+1, j)   \n",
    "            _beta = torch.matmul(emission_matrix[:, obs] *  A, beta[:, -(i+1)])\n",
    "            beta[:, -(i+2)] = torch.div(_beta, _beta.sum())\n",
    "        else:\n",
    "            beta[:, -(i+2)] = torch.matmul(emission_matrix[:, obs] *  A, beta[:, -(i+1)])\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximization Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gammas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma_i(t) = P(X_t = i | Y, \\theta) = \\frac {\\alpha_i(t)  \\beta_i (t)}  {\\sum_{j}^{N}\\alpha_i(t) \\beta_i(t)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gammas(alpha, beta):\n",
    "    \n",
    "    # α(t, i) * B(t, i)\n",
    "    numerator = torch.mul(alpha, beta)\n",
    "        \n",
    "    # Σ(j, 1-->N) α(t, i) * B(t, i)\n",
    "    denomenator = torch.sum(numerator, dim = 0)\n",
    "        \n",
    "    # γ(t, i) = α(t, i) * B(t, i) / Σ(j, 1-->N) α(t, i) * B(t, i)\n",
    "    gamma_i = torch.div(numerator, denomenator)\n",
    "    \n",
    "    return gamma_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\zeta_{ij}(t) = P(X_t = i, X_{t+1} = \\frac {P(X_t = i, X_{t+1} = j, Y | \\theta)} {P( Y|\\theta)} = j | Y, \\theta) = \\frac {\\alpha_i (t) a_{ij} \\beta_j(t+1) b_j(y_{t+1})} {{\\sum_{i=1}^{N}} \\sum_{j=1}^{N} \\alpha_i (t) a_{ij} \\beta_j(t+1) b_j(y_{t+1})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zetas(alpha, obs_seq):\n",
    "\n",
    "    zetas = []\n",
    "    for t, fwd in enumerate(alpha.transpose(1, 0)):\n",
    "        \n",
    "        # α(t,i) * A(i, j)\n",
    "        x = fwd*torch.transpose(A, 1, 0)\n",
    "        \n",
    "        # α(t,i) * A(i, j) * B(t+1, j) * β(t+1, j) \n",
    "        numerator = torch.transpose(x, 1, 0) * emission_matrix[:, obs_seq[t+1]] * beta[:, t+1]\n",
    "        \n",
    "        # P(Y|θ) = Σ(i, 1-->N) Σ(j, 1-->N) (α(t,i ) * A(i, j) * B(t+1, j) * β(t+1, j)\n",
    "        denomenator = torch.sum(numerator, dim=0).sum(dim=0)\n",
    "\n",
    "        # ζt(i, j) = α(t,i) * A(i, j) * B(t+1, j) * β(t+1, j) / Σ(i, 1-->N) Σ(j, 1-->N) (α(t,i ) * A(i, j) * B(t+1, j) * β(t+1, j)\n",
    "        zeta = torch.div(numerator, denomenator)\n",
    "        \n",
    "        zetas.append(zeta)\n",
    "    \n",
    "    # Σ(1-->T-1) ζt(i, j)\n",
    "    summed_zetas = torch.stack(zetas, dim = 0).sum(dim = 0)\n",
    "\n",
    "    return summed_zetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-estimate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hidden state distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\pi_i^* = \\gamma_i(1) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_{ij}^* = \\frac {\\sum_{t=1}^{T-1} \\zeta_{ij}(t)} {\\sum_{t=1}^{T-1} \\gamma_i(t)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emission matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b_i^*(\\nu_k) = \\frac {1_{y_t = \\nu_k} \\gamma_i(t)} {\\sum_{t=1}^{T} \\gamma_i(t)}$\n",
    "\n",
    "where\n",
    "\n",
    "$ 1_{y_t = \\nu_k} = \\begin{cases}\n",
    "    1 & \\text{if } y_t = \\nu_k\\\\\n",
    "    0              & \\text{otherwise}\n",
    "\\end{cases} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_estimate_parameters(emission_matrix, alpha, beta):\n",
    "    \n",
    "    # γ(t, i)\n",
    "    step_gammas = calculate_gammas(alpha, beta)\n",
    "\n",
    "    ##################################################\n",
    "    # Re-estimate initial probabilities\n",
    "    ##################################################\n",
    "    \n",
    "    new_pi = step_gammas[:, 0]\n",
    "    \n",
    "    ##################################################\n",
    "    # Re-estimate transition matrix\n",
    "    ##################################################\n",
    "    \n",
    "    # Σ(1-->T-1) ζt(i, j)\n",
    "    summed_zetas = calculate_zetas(alpha[:, :-1], obs_sequence)\n",
    "    # Σ(1-->T-1) γ(t, i)\n",
    "    summed_gammas = torch.sum(step_gammas[:, :-1], dim = 1)\n",
    "    # a^(i, j) = Σ(1-->T-1) ζt(i, j) / Σ(1-->T-1) γ(t, i)\n",
    "    new_transition_matrix = torch.div(summed_zetas, summed_gammas.view(-1, 1))\n",
    "\n",
    "    ##################################################\n",
    "    # Re-estimate emission matrix\n",
    "    ##################################################\n",
    "\n",
    "    # Σ(1-->T) γ(t, i)\n",
    "    summed_gammas = torch.sum(step_gammas, dim = 1)\n",
    "    state_indices = [np.where(obs_sequence == searchval)[0] for searchval in set(obs_sequence)]\n",
    "    new_emission_matrix = [expected_output_occurrence(value, step_gammas, summed_gammas) for value in state_indices]\n",
    "    new_emission_matrix = torch.stack(new_emission_matrix, dim = 0).transpose(1, 0)\n",
    "\n",
    "    return new_pi, new_transition_matrix, new_emission_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the implementation of the above algorithms we will use a numeric example in the following [link](http://www.cs.rochester.edu/u/james/CSC248/Lec11.pdf), and the results of the first pass will be compared as a form of sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric example: 1 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation sequence\n",
    "obs_sequence = np.array([0, 1, 2, 2])\n",
    "\n",
    "# Initial state distribution\n",
    "pi = np.array([0.8, 0.2])\n",
    "pi = torch.from_numpy(pi)\n",
    "\n",
    "# Initial transition matrix\n",
    "A = np.array([[0.6, 0.4], [0.3, 0.7]])\n",
    "A = torch.from_numpy(A)\n",
    "\n",
    "# Initial emission matrix\n",
    "emission_matrix = np.array([[0.3, 0.4, 0.3], [0.4, 0.3, 0.3]])\n",
    "emission_matrix = torch.from_numpy(emission_matrix)\n",
    "\n",
    "# Initialization of alpha & beta tensors\n",
    "shape = [A.shape[0], len(obs_sequence)]\n",
    "alpha = torch.zeros(shape, dtype = torch.float64)\n",
    "beta = torch.zeros(shape, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\alpha_i(t) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = forward(emission_matrix, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2400, 0.0672, 0.0162, 0.0045],\n",
       "        [0.0800, 0.0456, 0.0176, 0.0056]], dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\beta_i(t) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = backward(obs_sequence, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0324, 0.0900, 0.3000, 1.0000],\n",
       "        [0.0297, 0.0900, 0.3000, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximization step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma_i(t) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = calculate_gammas(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7660, 0.5957, 0.4787, 0.4436],\n",
       "        [0.2340, 0.4043, 0.5213, 0.5564]], dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\zeta_{ij}(t) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "zetas = calculate_zetas(alpha[:, :-1], obs_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1553, 0.6851],\n",
       "        [0.3628, 0.7968]], dtype=torch.float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-estimated parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pi, new_transition_matrix, new_emission_matrix = re_estimate_parameters(emission_matrix, alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\pi_i^* $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7660, 0.2340], dtype=torch.float64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ a_{ij}^* $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6277, 0.3723],\n",
       "        [0.3128, 0.6872]], dtype=torch.float64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ b_i^*(\\nu_k) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3354, 0.2608, 0.4038],\n",
       "        [0.1364, 0.2356, 0.6280]], dtype=torch.float64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_emission_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
